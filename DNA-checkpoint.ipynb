{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b4492a",
   "metadata": {},
   "source": [
    "# DNA Sequence Classification using Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f55470",
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_table('D:\\VIT\\Capstone\\Review2\\human_data.txt')\n",
    "human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf40f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "human.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"D:\\VIT\\Capstone\\Review2\\gene family.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c571b60c",
   "metadata": {},
   "source": [
    "### We will basically apply the k-mers to the human data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99124aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
    "def getKmers(sequence, size=6):\n",
    "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de95591",
   "metadata": {},
   "outputs": [],
   "source": [
    "human['words'] = human.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "human = human.drop('sequence', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3527e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "human.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccf52b",
   "metadata": {},
   "source": [
    "### convert the lists of k-mers for each gene into string sentences of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_texts = list(human['words'])\n",
    "for item in range(len(human_texts)):\n",
    "    human_texts[item] = ' '.join(human_texts[item])\n",
    "y_data = human.iloc[:, 0].values   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dea1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa851ab",
   "metadata": {},
   "source": [
    "### Now we will apply the BAG OF WORDS using CountVectorizer using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range=(4,4))\n",
    "X = cv.fit_transform(human_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed875f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd7358e",
   "metadata": {},
   "source": [
    "### If we have a look at class balance we can see we have relatively balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e7d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human['class'].value_counts().sort_index().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b0b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the human dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y_data, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15cdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,cross_val_score,cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec836093",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1s = []\n",
    "y=y_data.copy()\n",
    "print(\"Decision Classifier :\")\n",
    "for i,(train_index,val_index)  in enumerate(StratifiedKFold(n_splits=5,shuffle=True,random_state=42).split(X,y)):\n",
    "    dt =DecisionTreeClassifier()\n",
    "    dt.fit(X[train_index],y[train_index])\n",
    "    pred=dt.predict(X[val_index])\n",
    "    accuracy, precision, recall, f1 = get_metrics(y[val_index], pred)\n",
    "    print(str(i)+\" Iteration : Accuracy = %.5f     F1_Score = %.5f\" % (accuracy, f1))\n",
    "    acc.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "acc_dt = max(acc)\n",
    "f1s_dt = max(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "f1s = []\n",
    "y=y_data.copy()\n",
    "print(\"Random Forest Classifier :\")\n",
    "for i,(train_index,val_index)  in enumerate(StratifiedKFold(n_splits=5,shuffle=True,random_state=42).split(X,y)):\n",
    "    rf = RandomForestClassifier(n_jobs=-1)\n",
    "    rf.fit(X[train_index],y[train_index])\n",
    "    pred=rf.predict(X[val_index])\n",
    "    accuracy, precision, recall, f1 = get_metrics(y[val_index], pred)\n",
    "    print(str(i)+\" Iteration : Accuracy = %.5f     F1_Score = %.5f\" % (accuracy, f1))\n",
    "    acc.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "acc_rf = max(acc)\n",
    "f1s_rf = max(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7e74a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Used Grid Search to find the best Hyperparameters.\n",
    "acc = []\n",
    "f1s = []\n",
    "print(\"Naive Bayes Classifier :\")\n",
    "for i,(train_index,val_index)  in enumerate(StratifiedKFold(n_splits=5,shuffle=True,random_state=42).split(X,y)):\n",
    "    classifier = MultinomialNB(alpha=0.1)\n",
    "    classifier.fit(X[train_index],y[train_index])\n",
    "    pred=classifier.predict(X[val_index])\n",
    "    accuracy, precision, recall, f1 = get_metrics(y[val_index], pred)\n",
    "    print(str(i)+\" Iteration : Accuracy = %.5f    F1_Score = %.5f\" % (accuracy, f1))\n",
    "    acc.append(accuracy)\n",
    "    f1s.append(f1)\n",
    "acc_nb = max(acc)\n",
    "f1s_nb = max(f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "scores=[\"Decision Tree\",\"Random Forest\",\"Naive Bayes\"]\n",
    "accscore=[acc_dt,acc_rf,acc_nb]\n",
    "f1score=[f1s_dt,f1s_rf,f1s_nb]\n",
    "w=0.3\n",
    "bar1=np.arange(len(scores))\n",
    "bar2=[i+w for i in bar1]\n",
    "\n",
    "plt.bar(bar1,accscore,w,label=\"accuracy\")\n",
    "plt.bar(bar2,f1score,w,label=\"f1score\")\n",
    "plt.xticks(bar1, scores)\n",
    "plt.legend()\n",
    "plt.title(\"Comparision Between Models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84265973",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bar1)\n",
    "print(bar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.20, \n",
    "                                                    random_state=42)\n",
    "nb_ =MultinomialNB(alpha=0.01)\n",
    "nb_.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_.predict(X_test)\n",
    "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(nb_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f19fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,6))\n",
    "sns_plot = sns.heatmap(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')),cmap=\"YlGnBu\",annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0259a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"cm human.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e776df",
   "metadata": {},
   "source": [
    "### Testing our Model on Chimpanzee data and Dog Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9406cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp = pd.read_table('D:\\VIT\\Capstone\\Review2\\chimp_data.txt')\n",
    "dog = pd.read_table('D:\\VIT\\Capstone\\Review2\\dog_data.txt')\n",
    "chimp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776264ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp['words'] = chimp.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
    "dog['words'] = dog.apply(lambda x: getKmers(x['sequence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018779f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chimp_texts = list(chimp['words'])\n",
    "for item in range(len(chimp_texts)):\n",
    "    chimp_texts[item] = ' '.join(chimp_texts[item])\n",
    "y_c = chimp.iloc[:, 1].values                      \n",
    "\n",
    "dog_texts = list(dog['words'])\n",
    "for item in range(len(dog_texts)):\n",
    "    dog_texts[item] = ' '.join(dog_texts[item])\n",
    "y_d = dog.iloc[:, 1].values        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_chimp = cv.transform(chimp_texts)\n",
    "X_dog = cv.transform(dog_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286987a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_chimp.shape)\n",
    "print(X_dog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "plt.subplot(1,2,1)\n",
    "chimp['class'].value_counts().sort_index().plot.bar()\n",
    "plt.title(\"Chimpanzee Data\");\n",
    "plt.subplot(1,2,2)\n",
    "dog['class'].value_counts().sort_index().plot.bar()\n",
    "plt.title(\"Dog Data\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaafb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the chimp, dog and worm sequences\n",
    "y_pred_chimp = nb_.predict(X_chimp)\n",
    "y_pred_dog = nb_.predict(X_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706dac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on chimp genes\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(pd.crosstab(pd.Series(y_c, name='Actual'), pd.Series(y_pred_chimp, name='Predicted')))\n",
    "accuracy, precision, recall, f1 = get_metrics(y_c, y_pred_chimp)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pd.crosstab(pd.Series(y_c, name='Actual'), pd.Series(y_pred_chimp, name='Predicted'))\n",
    "sns.heatmap(mat,cmap=\"YlGnBu\",annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6486025",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"cm chimp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on dog genes\n",
    "print(\"Confusion matrix\\n\")\n",
    "print(pd.crosstab(pd.Series(y_d, name='Actual'), pd.Series(y_pred_dog, name='Predicted')))\n",
    "accuracy, precision, recall, f1 = get_metrics(y_d, y_pred_dog)\n",
    "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3088ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = (pd.crosstab(pd.Series(y_d, name='Actual'), pd.Series(y_pred_dog, name='Predicted')))\n",
    "sns.heatmap(mat,cmap=\"YlGnBu\",annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns_plot.get_figure()\n",
    "fig.savefig(\"cm dog.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c70bd9",
   "metadata": {},
   "source": [
    "# DNA Sequence Classification using Deep Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95f346",
   "metadata": {},
   "source": [
    "#### Transform Learning on Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524394bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/deep-learning-genomics-primer-master/deep-learning-genomics-primer-master/sequences.txt?token=GHSAT0AAAAAABRLL2JL5HIZVXVGPFJQTGJIYSCF56A'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/hlabel.txt?token=GHSAT0AAAAAABRLL2JLU2M3YKXQPAMZ6DJIYSCGAVQ'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    input_features, input_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=12, \n",
    "                 input_shape=(train_features.shape[1], 4)))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels, \n",
    "                    epochs=50, verbose=0, validation_split=0.25)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd385a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2da442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "predicted_labels = model.predict(np.stack(test_features))\n",
    "cm = confusion_matrix(np.argmax(test_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('tlh cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4b6d70",
   "metadata": {},
   "source": [
    "#### Transform Learning on Chimp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74add8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/chimpsequences.txt'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/chimplabel.txt'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "\n",
    "predicted_labels = model.predict(np.stack(input_features))\n",
    "\n",
    "cm = confusion_matrix(np.argmax(input_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('tlc cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb885b21",
   "metadata": {},
   "source": [
    "#### Transform Learning on Dog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835260e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/dogsequences.txt'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/doglabel.txt'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "\n",
    "predicted_labels = model.predict(np.stack(input_features))\n",
    "\n",
    "cm = confusion_matrix(np.argmax(input_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('tld cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed7bfa",
   "metadata": {},
   "source": [
    "#### CNN on Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4654a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/deep-learning-genomics-primer-master/deep-learning-genomics-primer-master/sequences.txt?token=GHSAT0AAAAAABRLL2JL5HIZVXVGPFJQTGJIYSCF56A'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/hlabel.txt?token=GHSAT0AAAAAABRLL2JLU2M3YKXQPAMZ6DJIYSCGAVQ'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    input_features, input_labels, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=12, \n",
    "                 input_shape=(train_features.shape[1], 4)))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "              metrics=['binary_accuracy'])\n",
    "model.summary()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b785d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_features, train_labels, \n",
    "                    epochs=50, verbose=0, validation_split=0.25)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629410cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "predicted_labels = model.predict(np.stack(test_features))\n",
    "cm = confusion_matrix(np.argmax(test_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('cnh cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c2602",
   "metadata": {},
   "source": [
    "#### CNN on Chimp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/chimpsequences.txt'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/chimplabel.txt'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "\n",
    "predicted_labels = model.predict(np.stack(input_features))\n",
    "\n",
    "cm = confusion_matrix(np.argmax(input_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('cnc cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeccdb9c",
   "metadata": {},
   "source": [
    "#### CNN on Dog Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2fc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCES_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/dogsequences.txt'\n",
    "\n",
    "sequences = requests.get(SEQUENCES_URL).text.split('\\n')\n",
    "sequences = list(filter(None, sequences))  # This removes empty sequences.\n",
    "\n",
    "# Let's print the first few sequences.\n",
    "pd.DataFrame(sequences, index=np.arange(1, len(sequences)+1), \n",
    "             columns=['Sequences']).head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# The LabelEncoder encodes a sequence of bases as a sequence of integers.\n",
    "integer_encoder = LabelEncoder()  \n",
    "# The OneHotEncoder converts an array of integers to a sparse matrix where \n",
    "# each row corresponds to one possible value of each feature.\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')   \n",
    "input_features = []\n",
    "\n",
    "for sequence in sequences:\n",
    "  integer_encoded = integer_encoder.fit_transform(list(sequence))\n",
    "  integer_encoded = np.array(integer_encoded).reshape(-1, 1)\n",
    "  one_hot_encoded = one_hot_encoder.fit_transform(integer_encoded)\n",
    "  input_features.append(one_hot_encoded.toarray())\n",
    "\n",
    "np.set_printoptions(threshold=40)\n",
    "input_features = np.stack(input_features)\n",
    "print(\"Example sequence\\n-----------------------\")\n",
    "print('DNA Sequence #1:\\n',sequences[0][:10],'...',sequences[0][-10:])\n",
    "print('One hot encoding of Sequence #1:\\n',input_features[0].T)\n",
    "\n",
    "\n",
    "LABELS_URL = 'https://raw.githubusercontent.com/pk13041991/DNA-SEQUENCING/master/doglabel.txt'\n",
    "\n",
    "labels = requests.get(LABELS_URL).text.split('\\n')\n",
    "labels = list(filter(None, labels))  # removes empty sequences\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(categories='auto')\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "input_labels = one_hot_encoder.fit_transform(labels).toarray()\n",
    "\n",
    "print('Labels:\\n',labels.T)\n",
    "print('One-hot encoded labels:\\n',input_labels.T)\n",
    "\n",
    "\n",
    "predicted_labels = model.predict(np.stack(input_features))\n",
    "\n",
    "cm = confusion_matrix(np.argmax(input_labels, axis=1), \n",
    "                      np.argmax(predicted_labels, axis=1))\n",
    "print('Confusion matrix:\\n',cm)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
    "\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)\n",
    "plt.title('Normalized confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')\n",
    "plt.xticks([0, 1]); plt.yticks([0, 1])\n",
    "plt.grid('off')\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > 0.5 else 'black')\n",
    "plt.savefig('cnd cm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675b5e4",
   "metadata": {},
   "source": [
    "### Comparision of All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b9401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "  \n",
    "# creating the dataset\n",
    "data = {'Decision Classifier':0.56, 'Random Forest':0.40, 'Naive Bayes':0.34, \n",
    "'CNN':0.42, 'Transform Learning':0.38}\n",
    "courses = list(data.keys())\n",
    "values = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(courses, values, color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Approaches followe\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Performance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "  \n",
    "# creating the dataset\n",
    "data = {'Decision Classifier':82.6, 'Random Forest':91.8, 'Navie Bayes':98.0, 'CNN':91.45,\n",
    "        'Transform Learning':94.57}\n",
    "courses = list(data.keys())\n",
    "values = list(data.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot0\n",
    "plt.bar(courses, values, color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Approaches followe\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Performance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
